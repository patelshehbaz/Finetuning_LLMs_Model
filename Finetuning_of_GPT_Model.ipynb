{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lTr2zZQFKUBQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7d2028e-8ffa-42ec-da60-922f92c97413"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [{'role': 'system',\n",
              "   'content': 'Marv is a factual chatbot that is also sarcastic.'},\n",
              "  {'role': 'user', 'content': 'How far is the Moon from Earth?'},\n",
              "  {'role': 'assistant',\n",
              "   'content': 'Around 384,400 kilometers. Give or take a few, like that really matters.'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who wrote 'Romeo and Juliet'?\"}, {\"role\": \"assistant\", \"content\": \"Oh, just some guy named William Shakespeare. Ever heard of him?\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"How far is the Moon from Earth?\"}, {\"role\": \"assistant\", \"content\": \"Around 384,400 kilometers. Give or take a few, like that really matters.\"}]}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"system\n",
        "user\n",
        "assistant\"\"\""
      ],
      "metadata": {
        "id": "uce_AtjsMVbP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "39f1e70f-c5a2-45b4-fda7-3197e607888f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'system\\nuser\\nassistant'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "# Install the OpenAI Python client library using pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_CkJye0M_-u",
        "outputId": "6eeaf01d-d3b6-4957-bf29-631066ea9eff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.37.0-py3-none-any.whl (337 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.0/337.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.37.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "OPENAI_API_KEY=userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "xQBch3UWNN65"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "fknWrNoxNAFU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.files.create(\n",
        "  file=open(\"mydata.jsonl\", \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")\n",
        "# Use the OpenAI client to create a file for the purpose of fine-tuning\n",
        "# file: Open the file \"mydata.jsonl\" in read-binary mode\n",
        "# purpose: Specify the purpose of the file as \"fine-tune\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "jFdwOZomMdTj",
        "outputId": "5485232a-4e8b-4625-cf77-0a76e593321c",
        "collapsed": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'mydata.jsonl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-cce96abf3fb6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m client.files.create(\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mydata.jsonl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mpurpose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fine-tune\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'mydata.jsonl'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files = client.files.list()\n",
        "# List all files associated with the OpenAI client\n",
        "# The returned list contains metadata about each file"
      ],
      "metadata": {
        "id": "ms1leDCvQNMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files"
      ],
      "metadata": {
        "id": "OWo_EQwBQN3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file in files:\n",
        "    # Iterate through each file in the list of files\n",
        "\n",
        "    if file.purpose == \"fine-tune\":\n",
        "        # Check if the purpose of the file is \"fine-tune\"\n",
        "\n",
        "        training_file_id = file.id\n",
        "        # Assign the file ID to the variable training_file_id\n",
        "\n",
        "        break\n",
        "        # Exit the loop once the first matching file is found"
      ],
      "metadata": {
        "id": "dBQIZbSaQSOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.fine_tuning.jobs.create(\n",
        "    training_file=training_file_id,\n",
        "    # Specify the ID of the training file to be used for fine-tuning\n",
        "\n",
        "    model=\"gpt-3.5-turbo\"\n",
        "    # Specify the model to be fine-tuned, in this case \"gpt-3.5-turbo\"\n",
        ")\n",
        "# Create a fine-tuning job using the specified training file and model"
      ],
      "metadata": {
        "id": "0Kc6g0PNQMJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.fine_tuning.jobs.list()\n",
        "# List all fine-tuning jobs associated with the OpenAI client\n",
        "# The returned list contains metadata about each fine-tuning job"
      ],
      "metadata": {
        "id": "y5KAQKI9ObzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.fine_tuning.jobs.retrieve(\"ftjob-QHPvVr4IMBVq0SIUOJK4byBz\")\n",
        "# Retrieve details of the fine-tuning job with the specified job ID \"ftjob-QHPvVr4IMBVq0SIUOJK4byBz\"\n",
        "# The returned object contains metadata and status information about the fine-tuning job"
      ],
      "metadata": {
        "id": "59wgSPwgQwJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-0125\",\n",
        "  # Specify the model to be used for generating chat completions\n",
        "\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    # Define the system message to set the assistant's behavior\n",
        "\n",
        "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
        "    # Define the user message to initiate the conversation\n",
        "  ]\n",
        ")\n",
        "# Create a chat completion using the specified model and messages\n",
        "\n",
        "print(completion.choices[0].message)\n",
        "# Print the generated message from the chat completion"
      ],
      "metadata": {
        "id": "T6XklRETQ0q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import csv\n",
        "\n",
        "# Replace 'your_path_here' with the path to the directory containing your file on Google Drive.\n",
        "# Make sure to keep '/content/drive/My Drive/' at the beginning.\n",
        "\n",
        "path_to_file = '/content/parenting_coach1.csv'\n",
        "# Path to the input CSV file\n",
        "\n",
        "output_path = '/content/parenting_coach1.jsonl'\n",
        "# Path to the output JSONL file\n",
        "\n",
        "# Open the CSV file and read each line\n",
        "with open(path_to_file, 'r', newline='', encoding='utf-8') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file)\n",
        "    # Create a CSV reader object\n",
        "\n",
        "    with open(output_path, 'w', encoding='utf-8') as jsonl_file:\n",
        "        # Open the output JSONL file for writing\n",
        "\n",
        "        for row in csv_reader:\n",
        "            json_str = row[0]\n",
        "            # Read the first column from each row (assuming it contains JSON strings)\n",
        "\n",
        "            json_obj = json.loads(json_str)\n",
        "            # Parse the JSON string into a Python dictionary\n",
        "\n",
        "            jsonl_file.write(json.dumps(json_obj) + '\\n')\n",
        "            # Convert the dictionary back to a JSON string and write it to the JSONL file\n",
        "\n",
        "print(f\"Conversion complete. The JSONL file is saved as '{output_path}'.\")\n",
        "# Print a confirmation message once the conversion is complete\n"
      ],
      "metadata": {
        "id": "n3G6lJKfS0nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.files.create(\n",
        "  file=open(\"/content/parenting_coach1.jsonl\", \"rb\"),\n",
        "  # Open the JSONL file in read-binary mode\n",
        "\n",
        "  purpose=\"fine-tune\"\n",
        "  # Specify the purpose of the file as \"fine-tune\"\n",
        ")\n",
        "# Use the OpenAI client to create a file for the purpose of fine-tuning"
      ],
      "metadata": {
        "id": "QIndH3TVTmrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "suffix_name = \"abc123\"\n",
        "# Define a suffix name to be used for the fine-tuning job\n",
        "\n",
        "response = client.fine_tuning.jobs.create(\n",
        "    training_file='file-n8b1hgGcRpVnXxkKgzwynThB',\n",
        "    # Specify the ID of the training file to be used for fine-tuning\n",
        "\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    # Specify the model to be fine-tuned, in this case \"gpt-3.5-turbo\"\n",
        "\n",
        "    suffix=suffix_name\n",
        "    # Use the defined suffix name for the fine-tuning job\n",
        ")\n",
        "# Create a fine-tuning job using the specified training file, model, and suffix\n"
      ],
      "metadata": {
        "id": "7h_q4d08TvGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_id = response[\"id\"]\n",
        "# Extract the job ID from the response of the fine-tuning job creation\n",
        "# Assign the job ID to the variable job_id"
      ],
      "metadata": {
        "id": "uPLdUz8LnygE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "id": "54ILLZRMn1xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.fine_tuning.jobs.list()\n",
        "# List all fine-tuning jobs associated with the OpenAI client\n",
        "# The returned list contains metadata about each fine-tuning job"
      ],
      "metadata": {
        "id": "oPyUfgQsT4rH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the state of a fine-tuning job\n",
        "response = client.fine_tuning.jobs.retrieve('ftjob-SgXfk2q90cvgzebEnzIsNPlq')\n",
        "# Retrieve details of the fine-tuning job with the specified job ID 'ftjob-SgXfk2q90cvgzebEnzIsNPlq'\n",
        "# The returned object contains metadata and status information about the fine-tuning job"
      ],
      "metadata": {
        "id": "UBtbT0ajoQCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.fine_tuned_model"
      ],
      "metadata": {
        "id": "dszMwV0gpAmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tuned_model_id = response[\"fine_tuned_model\"]"
      ],
      "metadata": {
        "id": "1OlXW9LmofTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tuned_model_id = response[\"fine_tuned_model\"]\n",
        "# Extract the fine-tuned model ID from the response of the fine-tuning job retrieval\n",
        "# Assign the fine-tuned model ID to the variable fine_tuned_model_id"
      ],
      "metadata": {
        "id": "v25H9DuFoOJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model='gpt-3.5-turbo-0125',\n",
        "  # Specify the model to be used for generating chat completions\n",
        "\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    # Define the system message to set the assistant's behavior\n",
        "\n",
        "    {\"role\": \"user\", \"content\": \"my son does not do the homework what should i do?\"}\n",
        "    # Define the user message with a question about the son's homework\n",
        "  ]\n",
        ")\n",
        "# Create a chat completion using the specified model and messages\n",
        "\n",
        "print(completion.choices[0].message)\n",
        "# Print the generated message from the chat completion"
      ],
      "metadata": {
        "id": "Z1sBpui9T9LP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show openai"
      ],
      "metadata": {
        "id": "9gawSzfSUd3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "# Import the necessary libraries: json for handling JSON data and pandas for data manipulation\n",
        "\n",
        "DEFAULT_SYSTEM_PROMPT = 'You are a teaching assistant for Machine Learning. You should help the user to answer his question.'\n",
        "# Define the default system prompt to be used in the dataset\n",
        "\n",
        "def create_dataset(question, answer):\n",
        "    # Function to create a dataset entry from a question and answer pair\n",
        "    return {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": DEFAULT_SYSTEM_PROMPT},\n",
        "            # Include the system message with the default prompt\n",
        "\n",
        "            {\"role\": \"user\", \"content\": question},\n",
        "            # Include the user's question\n",
        "\n",
        "            {\"role\": \"assistant\", \"content\": answer},\n",
        "            # Include the assistant's answer\n",
        "        ]\n",
        "    }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Main block to execute the script\n",
        "    df = pd.read_csv(\"path/to/file.csv\", encoding='cp1252')\n",
        "    # Read the CSV file into a pandas DataFrame, using the specified encoding\n",
        "\n",
        "    with open(\"train.jsonl\", \"w\") as f:\n",
        "        # Open the output JSONL file for writing\n",
        "\n",
        "        for _, row in df.iterrows():\n",
        "            # Iterate over each row in the DataFrame\n",
        "\n",
        "            example_str = json.dumps(create_dataset(row[\"Question\"], row[\"Answer\"]))\n",
        "            # Convert the dataset entry to a JSON string\n",
        "\n",
        "            f.write(example_str + \"\\n\")\n",
        "            # Write the JSON string to the JSONL file, followed by a newline\n"
      ],
      "metadata": {
        "id": "_4cf7Ja8VJlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = client.files.create(\n",
        "  file=open(\"/content/parenting_coach1.jsonl\", \"rb\"),\n",
        "  # Open the JSONL file in read-binary mode\n",
        "\n",
        "  purpose=\"fine-tune\"\n",
        "  # Specify the purpose of the file as \"fine-tune\"\n",
        ")\n",
        "# Use the OpenAI client to create a file for the purpose of fine-tuning\n"
      ],
      "metadata": {
        "id": "vbZMJu6sp7z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job = client.fine_tuning.jobs.create(\n",
        "  training_file=file.id,\n",
        "  # Specify the ID of the training file to be used for fine-tuning\n",
        "\n",
        "  model=\"gpt-3.5-turbo\"\n",
        "  # Specify the model to be fine-tuned, in this case \"gpt-3.5-turbo\"\n",
        ")\n",
        "# Create a fine-tuning job using the specified training file and model"
      ],
      "metadata": {
        "id": "wsWWgykGqFvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file.id\n",
        "# Retrieve the ID of the file that was created and assigned for fine-tuning"
      ],
      "metadata": {
        "id": "bLSSWgmHqRsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job.id\n",
        "# Retrieve the ID of the fine-tuning job that was created"
      ],
      "metadata": {
        "id": "osA8GBCwqV5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job = client.fine_tuning.jobs.retrieve(job.id)\n",
        "# Retrieve details of the fine-tuning job using the job ID\n",
        "# The returned object contains metadata and status information about the fine-tuning job\n"
      ],
      "metadata": {
        "id": "875tcLc3qB-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job.fine_tuned_model\n",
        "# Retrieve the ID of the fine-tuned model from the job details"
      ],
      "metadata": {
        "id": "aYTAdAIeqZpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=job.fine_tuned_model,\n",
        "  # Use the fine-tuned model for generating chat completions\n",
        "\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    # Define the system message to set the assistant's behavior\n",
        "\n",
        "    {\"role\": \"user\", \"content\": \"how to fix email issue\"}\n",
        "    # Define the user message with a question about fixing an email issue\n",
        "  ]\n",
        ")\n",
        "# Create a chat completion using the specified model and messages\n",
        "\n",
        "print(completion.choices[0].message)\n",
        "# Print the generated message from the chat completion\n"
      ],
      "metadata": {
        "id": "q0gADIzlqNO5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}